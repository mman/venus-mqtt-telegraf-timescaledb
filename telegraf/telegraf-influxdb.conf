# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "5s"

  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"

  ## Collected metrics are rounded to the precision specified. Precision is
  ## specified as an interval with an integer + unit (e.g. 0s, 10ms, 2us, 4s).
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  ##
  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s:
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ##
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = "0s"

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = true

# Read metrics from MQTT topic(s)
[[inputs.mqtt_consumer]]
servers = ["tcp://${VENUS_HOST}:1883"]
topics = [
  "N/#"
]

data_format = "json_v2"
  [[inputs.mqtt_consumer.json_v2]]
    [[inputs.mqtt_consumer.json_v2.field]]
      path = "value"


# STEP 1: drop measurements without value
[[processors.starlark]]
  order = 1

  source = '''
def apply(metric):
  # drop measurements without value
  value = metric.fields.get("value")
  if value == None:
    return None
  # drop measurements with 'object' type value
  if type(value) == "object":
    return None
  return metric
'''


# STEP 2: extract appropriate tags
[[processors.regex]]
  order = 2

  # extract `portalId` from mqtt topic
  [[processors.regex.tags]]
    key = "topic"
    pattern = '^N\/([a-zA-Z0-9]+)\/(.*)$'
    replacement = "${1}"
    result_key = "portalId"

  # extract `name` from mqtt topic (same as portalId for now)
  [[processors.regex.tags]]
    key = "topic"
    pattern = '^N\/([a-zA-Z0-9]+)\/(.*)$'
    replacement = "${1}"
    result_key = "name"

  # extract `instanceNumber` from mqtt topic
  [[processors.regex.tags]]
    key = "topic"
    pattern = '^N\/([a-zA-Z0-9]+)\/([a-zA-Z0-9]+)\/([0-9]+)\/(.*)$'
    replacement = "${3}"
    result_key = "instanceNumber"

  # drop `N`, `portalId`, and `instanceNumber` from mqtt topic
  [[processors.regex.tags]]
    key = "topic"
    pattern = '^N\/([a-zA-Z0-9]+)\/([a-zA-Z0-9]+)\/([0-9]+)\/(.*)$'
    replacement = "${2}/${4}"

# STEP 3: rename measurement from default mqtt_consumer to parsed topic
[[processors.converter]]
  order = 3

  # use `topic` tag as measurement name
  [processors.converter.tags]
    measurement = ["topic"]

[[outputs.file]]
# files = ["stdout"]
# # data_format = "json"
# #json_timestamp_units = "1s"
data_format = "influx"
influx_sort_fields = true

[[outputs.influxdb]]
  urls = ["http://host.docker.internal:8086"]
  username = "venus"
  password = "s3cr4t"
  database = "venus"
